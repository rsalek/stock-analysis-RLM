# @title üöÄ Phase 1: Stock Analysis Engine (Context Aware & Full Pipeline)
#
# DESCRIPTION:
# This script performs the raw analysis using the NEW Google GenAI SDK (v1.0+).
# 1. Reads prompts (1-13) and input files (PDFs, HTML, TXT) from Drive.
# 2. Uploads context to Gemini using the modern Client API.
# 3. Runs analysis steps in a specific LOGICAL ORDER.
# 4. **FIXED:** Force-feeds Ticker to prevent "What company?" loops.
# 5. **FIXED:** Upload method uses 'file' parameter to avoid keyword errors.

import os
import re
import time
import shutil
import glob
import subprocess
import sys
import importlib.util
from pathlib import Path

PHASE0_AVAILABLE = importlib.util.find_spec("phase0_rlm") is not None
if PHASE0_AVAILABLE:
    from phase0_rlm import bm25_index as phase0_bm25_index
    from phase0_rlm import chunking as phase0_chunking
    from phase0_rlm import document_store as phase0_document_store
    from phase0_rlm import tools as phase0_tools
# ==========================================
# üì¶ DEPENDENCIES
# ==========================================
def install_dependencies():
    """Checks and installs the new Google GenAI SDK if missing."""
    print("‚öôÔ∏è Installing new Google GenAI SDK...")
    try:
        import google.genai
        print("   ‚úÖ google-genai is installed.")
    except ImportError:
        subprocess.check_call([sys.executable, "-m", "pip", "install", "-U", "google-genai"])
        print("   ‚úÖ google-genai installed successfully.")

install_dependencies()

from google import genai
from google.genai import types
from google.colab import drive

# ==========================================
# ‚öôÔ∏è CONFIGURATION
# ==========================================

# 1. API SETUP
API_KEY = os.environ.get("GEMINI_API_KEY", "").strip()

# 2. GOOGLE DRIVE PATHS
BASE_DRIVE_PATH = os.environ.get("BASE_DRIVE_PATH", "/content/drive/My Drive/Stock_Analysis")
PROMPTS_DIR = os.path.join(BASE_DRIVE_PATH, "Prompts8")
INPUT_DIR = os.path.join(BASE_DRIVE_PATH, "Input")
RESULTS_BASE_DIR = os.path.join(BASE_DRIVE_PATH, "Results")

# 3. MODEL SELECTION
MODEL_NAME = "gemini-3-pro-preview"

# 4. EXECUTION ORDER
EXECUTION_ORDER = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]

# ==========================================
# üõ†Ô∏è HELPER FUNCTIONS
# ==========================================

def setup_environment():
    """Mounts Drive and initializes the GenAI client."""
    if os.environ.get("PHASE1_SMOKE") == "1":
        print("‚ö†Ô∏è Smoke mode enabled. Skipping Drive mount and API setup.")
        return None

    print("üìÇ Mounting Google Drive...")
    drive.mount('/content/drive')
    if not API_KEY:
        raise EnvironmentError("‚ùå GEMINI_API_KEY is not set. Provide it via environment variables.")
    print(f"üîë Configuring Gemini Client with model: {MODEL_NAME}...")
    client = genai.Client(api_key=API_KEY)

    if not os.path.exists(PROMPTS_DIR):
        raise FileNotFoundError(f"‚ùå Prompts directory not found at: {PROMPTS_DIR}")
    if not os.path.exists(INPUT_DIR):
        os.makedirs(INPUT_DIR)

    return client

def get_prompts_by_id(prompt_dir):
    """Reads all prompts and returns a dictionary mapped by Step Number."""
    prompts = {}
    print(f"üìñ Reading prompts from {prompt_dir}...")
    files = glob.glob(os.path.join(prompt_dir, "*.txt")) + glob.glob(os.path.join(prompt_dir, "*.md"))

    for filepath in files:
        filename = os.path.basename(filepath)
        match = re.match(r"(\d+)", filename)
        if match:
            step_num = int(match.group(1))
            with open(filepath, 'r', encoding='utf-8') as f:
                prompts[step_num] = f.read()
            print(f"   Found Prompt {step_num}: {filename}")

    if not prompts:
        raise ValueError("‚ùå No numbered prompt files found!")
    return prompts

def upload_knowledge_base(client, input_dir):
    """Uploads files using the NEW client.files.upload method."""
    file_objects = []
    supported = ['.pdf', '.txt', '.md', '.csv', '.jpg', '.png', '.html', '.htm']

    print(f"üì§ Scanning Knowledge Base in {input_dir}...")
    files_found = [f for f in os.listdir(input_dir) if os.path.splitext(f)[1].lower() in supported]

    if not files_found:
        print("‚ö†Ô∏è No input files found. Using generic knowledge.")
        return []

    for filename in files_found:
        file_path = os.path.join(input_dir, filename)
        print(f"   Uploading: {filename}...")
        try:
            # FIX: Using 'file' kwarg (standard for v1.0) or positional if needed
            uploaded_file = client.files.upload(file=file_path)

            # Wait for processing
            while uploaded_file.state.name == "PROCESSING":
                print("   ...processing...", end='\r')
                time.sleep(2)
                uploaded_file = client.files.get(name=uploaded_file.name)

            if uploaded_file.state.name == "FAILED":
                print(f"‚ùå Failed to process {filename}")
                continue

            file_objects.append(uploaded_file)
            print(f"   ‚úÖ Ready: {filename}")

        except Exception as e:
            print(f"   ‚ùå Error uploading {filename}: {e}")

    return file_objects

def extract_phase(text):
    """Parses Step 1 output to find the Business Phase (1-6)."""
    match = re.search(r"Phase\s?[:\-]?\s?(\d)", text, re.IGNORECASE)
    return match.group(1) if match else "4"

def generate_with_retry(client, message_contents, max_retries=5):
    """Generates content with exponential backoff."""
    if os.environ.get("PHASE1_SMOKE") == "1":
        class _SmokeResponse:
            def __init__(self, text):
                self.text = text

        return _SmokeResponse("SMOKE MODE OUTPUT")

    base_delay = 15
    for attempt in range(max_retries):
        try:
            response = client.models.generate_content(
                model=MODEL_NAME,
                contents=message_contents
            )
            return response
        except Exception as e:
            if "429" in str(e) or "quota" in str(e).lower() or "503" in str(e):
                wait_time = base_delay * (attempt + 1)
                print(f"\n   üõë API Busy/Limit. Waiting {wait_time}s... ({attempt+1}/{max_retries})")
                time.sleep(wait_time)
            else:
                raise e
    raise Exception("‚ùå Max retries exceeded.")

def archive_inputs(input_dir, results_dir):
    """Moves processed input files to the result folder."""
    archive_path = os.path.join(results_dir, "Source_Docs")
    os.makedirs(archive_path, exist_ok=True)
    for f in os.listdir(input_dir):
        src, dst = os.path.join(input_dir, f), os.path.join(archive_path, f)
        if os.path.isfile(src): shutil.move(src, dst)
    print("‚úÖ Input folder cleared.")

def prepare_phase0_index(input_dir):
    if not PHASE0_AVAILABLE:
        return False

    try:
        phase0_document_store.ingest_drive_paths([input_dir])
        phase0_chunking.chunk_documents()
        phase0_bm25_index.build_bm25_index()
    except Exception as exc:
        print(f"‚ö†Ô∏è Phase 0 ingest failed: {exc}")
        return False
    return True

def build_evidence_pack(ticker, step_num, prompt_template, k=12):
    if not PHASE0_AVAILABLE:
        return ""

    query_seed = prompt_template.replace("{TICKER}", ticker).replace("[Company Name]", ticker)
    query = f"{ticker} step {step_num} {query_seed[:240]}"
    results = phase0_tools.search(query, k=k, ticker=ticker)
    passages = []
    for result in results:
        chunk = phase0_tools.open_chunk(result.get("doc_id"), result.get("chunk_id"))
        if chunk:
            passages.append(chunk)

    if not passages:
        return ""

    evidence_blocks = []
    for passage in passages:
        location = f"{passage.get('doc_id')}:{passage.get('chunk_id')}"
        evidence_blocks.append(f"[{location}]\\n{passage.get('text', '')}")

    citations = phase0_tools.cite(passages, ticker=ticker)
    return "\n\n".join(evidence_blocks) + f"\n\nCitations:\n{citations}"

# ==========================================
# üöÄ MAIN WORKFLOW
# ==========================================

def run_analysis():
    client = setup_environment()

    ticker = os.environ.get("PHASE1_TICKER") or input("Enter Stock Ticker (e.g., TSLA): ")
    ticker = ticker.upper().strip()
    if not ticker: return

    # --- USER CONTEXT COLLECTION ---
    print("\n--- üíº Portfolio Context (Optional but Recommended) ---")
    if os.environ.get("PHASE1_SMOKE") == "1":
        has_position = False
    else:
        has_position = input("Do you currently own this stock? (y/n): ").lower().strip() == 'y'

    shares = "0"
    avg_cost = "0.00"
    target_alloc = "5" # Default 5%

    if has_position:
        shares = input("   Number of Shares: ").strip()
        avg_cost = input("   Average Cost ($): ").strip()

    if os.environ.get("PHASE1_SMOKE") == "1":
        target_alloc_input = ""
    else:
        target_alloc_input = input("   Target Portfolio Allocation % (Default 5): ").strip()
    if target_alloc_input: target_alloc = target_alloc_input

    # Construct the Context String
    user_context_str = f"""
    USER PORTFOLIO CONTEXT:
    - Current Shares: {shares}
    - Average Cost: ${avg_cost}
    - Target Allocation: {target_alloc}%
    - Current Status: {"Holding" if has_position else "Watching"}
    """

    stock_results_dir = os.path.join(RESULTS_BASE_DIR, ticker)
    os.makedirs(stock_results_dir, exist_ok=True)
    print(f"üìÇ Results will be saved to: {stock_results_dir}")

    all_prompts = get_prompts_by_id(PROMPTS_DIR)
    kb_files = upload_knowledge_base(client, INPUT_DIR)
    os.environ.setdefault("PHASE0_BASE_DRIVE_PATH", BASE_DRIVE_PATH)
    phase0_ready = prepare_phase0_index(INPUT_DIR)
    detected_phase = "Unknown"

    print("\n‚ö° STARTING ANALYSIS CHAIN ‚ö°")

    for step_num in EXECUTION_ORDER:
        if step_num not in all_prompts:
            print(f"‚ö†Ô∏è Warning: Step {step_num} prompt not found. Skipping.")
            continue

        print(f"\n--- Running Step {step_num} ---")
        prompt_template = all_prompts[step_num]

        message_contents = []
        if kb_files:
            message_contents.extend(kb_files)

        # --- CRITICAL FIX: OVERRIDE INJECTION ---
        override_header = f"""
        SYSTEM OVERRIDE:
        The user has ALREADY provided the company.
        TARGET COMPANY: {ticker} ({ticker})
        TARGET PHASE: {detected_phase}

        INSTRUCTIONS:
        1. Ignore any requests to "ask the user" for the company name.
        2. Proceed IMMEDIATELY with the analysis for {ticker}.
        3. Do NOT output "What company would you like me to analyze?".
        ------------------------------------------------------------
        """

        final_prompt = override_header + prompt_template.replace("{TICKER}", ticker).replace("[Company Name]", ticker)

        if phase0_ready:
            evidence_pack = build_evidence_pack(ticker, step_num, prompt_template, k=12)
            if evidence_pack:
                final_prompt += f"\n\nEvidence:\n{evidence_pack}"

        # Inject Phase Logic
        if step_num == 5 or step_num == 7:
            print(f"   ‚ÑπÔ∏è Injecting Phase {detected_phase} into instructions...")
            final_prompt += f"\n\nCRITICAL CONTEXT: Company is PHASE {detected_phase}. Use metrics for PHASE {detected_phase}."

        # Inject User Context
        if step_num == 12 or step_num == 13:
            print(f"   üíº Injecting Portfolio Context...")
            final_prompt += f"\n\n{user_context_str}\n\nINSTRUCTION: Use this specific portfolio data to tailor the Buy/Sell ladder and Behavioral Bias check."

        message_contents.append(final_prompt)

        try:
            response = generate_with_retry(client, message_contents)
            result_text = response.text

            if step_num == 1:
                detected_phase = extract_phase(result_text)
                print(f"   ‚úÖ Identified Business Phase: {detected_phase}")

            output_filename = f"Step_{step_num}_Output.md"
            with open(os.path.join(stock_results_dir, output_filename), "w", encoding="utf-8") as f:
                f.write(result_text)

            print(f"   üíæ Saved {output_filename}")
            print("   üí§ Cooling down (5s)...")
            time.sleep(5)

        except Exception as e:
            print(f"   ‚ùå Failed at Step {step_num}: {e}")

    # 5. Final Cleanup
    if kb_files:
        archive_inputs(INPUT_DIR, stock_results_dir)

    print(f"\nüéâ Analysis Complete for {ticker}!")
    print(f"üëâ Now run the 'Stock Report Generator' script to build the PDF.")

if __name__ == "__main__":
    run_analysis()
